{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "from tqdm.auto import tqdm\n",
    "from time import sleep\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data path:  data/adversarial_data/ionization_bubble/*.bmp\n",
      "output directory:  gan/outputs/basic_gan\n"
     ]
    }
   ],
   "source": [
    "# path = \"D:/adversarial_data/*.bmp\"\n",
    "path = 'data/adversarial_data/ionization_bubble/*.bmp'\n",
    "save_dir = 'gan/outputs/basic_gan'\n",
    "print(\"data path: \",path)\n",
    "print(\"output directory: \",save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 128\n",
    "img_width = 128\n",
    "channels = 1\n",
    "batch = 14\n",
    "epochs = 10000000\n",
    "dims = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, height, width):\n",
    "    img = resize(x,(height, width))\n",
    "    img /= 127.5-1\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_graph(dims=100, image_shape=(28,28,1)):\n",
    "    \n",
    "    gen_input = tf.keras.Input(shape=(dims,))\n",
    "    x = tf.keras.layers.Dense(256)(gen_input)\n",
    "    x = tf.keras.layers.LeakyReLU(0.3)(x)\n",
    "    x = tf.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "    x = tf.keras.layers.Dense(512)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.2)(x)\n",
    "    x = tf.keras.layers.BatchNormalization(momentum=0.8)(x)\n",
    "    x = tf.keras.layers.Dense(np.prod(image_shape),activation='tanh')(x)\n",
    "    x = tf.keras.layers.Reshape(image_shape)(x)\n",
    "    \n",
    "    generator = tf.keras.models.Model(gen_input, x)\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    generator.summary()\n",
    "    \n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_graph(height=128,width=128,channel=1):\n",
    "\n",
    "    disc_input = tf.keras.layers.Input(shape=(height,width,channel))\n",
    "    x = tf.keras.layers.Flatten()(disc_input)\n",
    "    x = tf.keras.layers.Dense(512)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = tf.keras.layers.Dense(256)(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    discriminator = tf.keras.models.Model(disc_input,x)\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(lr=0.0002,beta_1=0.5)\n",
    "    discriminator.compile(optimizer=opt,loss='binary_crossentropy')\n",
    "    discriminator.summary()\n",
    "    \n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_graph(disc_net, gen_net, dims=100):\n",
    "    disc_net.trainable=False\n",
    "    adv_input = tf.keras.Input(shape=(dims,))\n",
    "    adv_output = disc_net(gen_net(adv_input))\n",
    "    \n",
    "    adv_network = tf.keras.Model(inputs=adv_input, outputs=adv_output)\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(0.001,0.9)\n",
    "    adv_network.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    adv_network.summary()\n",
    "    \n",
    "    return adv_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\EmageSoft-1\\Anaconda3\\envs\\tf131\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16384)             8404992   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 128, 128, 1)       0         \n",
      "=================================================================\n",
      "Total params: 8,565,504\n",
      "Trainable params: 8,563,968\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gen_model = gen_graph(image_shape=(img_height,img_width,channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 128, 128, 1)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               8389120   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 8,520,705\n",
      "Trainable params: 8,520,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "disc_model = disc_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "model (Model)                (None, 128, 128, 1)       8565504   \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 1)                 8520705   \n",
      "=================================================================\n",
      "Total params: 17,086,209\n",
      "Trainable params: 8,563,968\n",
      "Non-trainable params: 8,522,241\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adv_net = adversarial_graph(disc_model,gen_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filelist,height,width):\n",
    "    X_train = []\n",
    "    for i in filelist:\n",
    "#         print(i)\n",
    "        img = io.imread(i,as_gray=True)\n",
    "        img= preprocess(img,height,width)\n",
    "        X_train.append(img)\n",
    "    X_train = np.array(X_train)\n",
    "    X_train = np.reshape(X_train,(-1,height, width, 1))\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = load_data(filelist,img_height,img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(epoch,dims,path):\n",
    "        r, c = 5,5\n",
    "        noise = np.random.normal(0,1,(r*c, dims))\n",
    "        \n",
    "        gen_imgs = gen_model.predict(noise)\n",
    "        \n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        fig, axs = plt.subplots(r,c)\n",
    "        count = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[count,:,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                count += 1\n",
    "        fig.savefig(path+'/%d.png'%epoch)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch_size, epochs, k,X_train,latent_dims):\n",
    "        \n",
    "        \n",
    "#     (X_train, _), (_,_) = mnist.load_data()\n",
    "    # Rescale -1 to 1\n",
    "#     X_train = X_train/ 127.5 - 1\n",
    "#     X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    #ground truths\n",
    "    real = np.ones((batch_size,1))\n",
    "    fake = np.zeros((batch_size,1))\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Algorithm 1\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        noise = np.random.normal(0,1,(batch_size, latent_dims))\n",
    "\n",
    "        gen_imgs = gen_model.predict(noise)\n",
    "\n",
    "        #Train the discriminator\n",
    "        d_loss_real = disc_model.train_on_batch(imgs,real)\n",
    "        d_loss_fake = disc_model.train_on_batch(gen_imgs, fake)\n",
    "        d_loss = 0.5*np.add(d_loss_real, d_loss_fake)\n",
    "#         print(d_loss)\n",
    "        #Train Generator\n",
    "        noise = np.random.normal(0,1, (batch_size, latent_dims))\n",
    "        g_loss = adv_net.train_on_batch(noise, real)\n",
    "#         print(g_loss)\n",
    "        #progress per epoch\n",
    "        print(\"%d [D loss: %f, accuracy: %.2f%%] [G loss:%f]\" % (i, d_loss, 100*d_loss, g_loss))\n",
    "\n",
    "        if i % k == 0:\n",
    "            sample_images(i,100,save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-263ead04cdc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-a381e33302bd>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(batch_size, epochs, k, X_train, latent_dims)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# Algorithm 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int32\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "train(batch,epochs,100000,gen,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
